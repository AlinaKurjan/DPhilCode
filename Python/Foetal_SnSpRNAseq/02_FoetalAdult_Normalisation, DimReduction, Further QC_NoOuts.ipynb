{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce23ee6e",
   "metadata": {},
   "source": [
    "# Run with scib-pipeline-R4.0 conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c81cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import scib\n",
    "import anndata\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "# Print date and time:\n",
    "import datetime\n",
    "e = datetime.datetime.now()\n",
    "print (\"Current date and time = %s\" % e)\n",
    "\n",
    "# set a working directory\n",
    "wdir = \"/mnt/da8aa2c4-0136-465b-87a2-d12a59afec55/akurjan/analysis/notebooks\"\n",
    "os.chdir( wdir )\n",
    "\n",
    "# folder structures\n",
    "QC_FOLDERNAME = \"foetal/results/QC/\"\n",
    "RESULTS_FOLDERNAME = \"foetal/results/Normalisation/\"\n",
    "FIGURES_FOLDERNAME = \"foetal/figures/Normalisation/\"\n",
    "\n",
    "if not os.path.exists(RESULTS_FOLDERNAME):\n",
    "    os.makedirs(RESULTS_FOLDERNAME)\n",
    "if not os.path.exists(FIGURES_FOLDERNAME):\n",
    "    os.makedirs(FIGURES_FOLDERNAME)\n",
    "\n",
    "# Set folder for saving figures into\n",
    "sc.settings.figdir = FIGURES_FOLDERNAME\n",
    "\n",
    "# Set other settings\n",
    "sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "sc.set_figure_params(dpi=150, fontsize=10, dpi_save=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savesvg(fname: str, fig, folder: str=FIGURES_FOLDERNAME) -> None:\n",
    "    \"\"\"\n",
    "    Save figure as vector-based SVG image format.\n",
    "    \"\"\"\n",
    "    fig.savefig(os.path.join(folder, fname), format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6abef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(os.path.join(QC_FOLDERNAME, 'adata_concat_filtered.h5ad'))\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e277e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata.layers['ambiguous'], adata.layers['matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580777b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting adata into separate objects that can be integrated separately.\n",
    "adult_adata = adata[adata.obs['agegroup'] == 'Adult', :]\n",
    "dev_adata = adata[adata.obs['agegroup'] != 'Adult', :]\n",
    "\n",
    "adata_dict = {'adult_adata': adult_adata, 'dev_adata': dev_adata}\n",
    "adata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e6d76",
   "metadata": {},
   "source": [
    "# NORMALISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f59bb",
   "metadata": {},
   "source": [
    "## Shifted logarithm normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef31c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    scaled_counts = sc.pp.normalize_total(adata, target_sum=None, inplace=False)\n",
    "    # log1p transform\n",
    "    adata.layers[\"log1p_norm\"] = sc.pp.log1p(scaled_counts[\"X\"], copy=True)\n",
    "    print(adata.layers[\"log1p_norm\"][1:10, 1:10])\n",
    "    adata_dict[i] = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in adata_dict.values():\n",
    "    print(adata.layers['log1p_norm'][0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ca6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in adata_dict.values():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    p1 = sns.histplot(adata.obs[\"total_counts\"], bins=100, kde=False, ax=axes[0])\n",
    "    axes[0].set_title(\"Total counts\")\n",
    "    p2 = sns.histplot(adata.layers[\"log1p_norm\"].sum(1), bins=100, kde=False, ax=axes[1])\n",
    "    axes[1].set_title(\"Shifted logarithm\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707b848",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION AND SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d714c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_uint_to_int_single(adata):\n",
    "    \"\"\"\n",
    "    Convert uint32 and uint64 dtypes in anndata object to int32 and int64 dtypes,\n",
    "    respectively. Prints a message for each conversion.\n",
    "    \"\"\"\n",
    "    # Check var and obs dtypes\n",
    "    for dtype in ['var', 'obs']:\n",
    "        dtype_data = getattr(adata, dtype)\n",
    "        if isinstance(dtype_data, np.ndarray):\n",
    "            # If dtype_data is a structured array, convert each field individually\n",
    "            for field in dtype_data.dtype.names:\n",
    "                if dtype_data[field].dtype == 'uint32':\n",
    "                    dtype_data[field] = dtype_data[field].astype('float32')\n",
    "                    print(f\"Converted {dtype}.{field} from uint32 to float32.\")\n",
    "                elif dtype_data[field].dtype == 'uint64':\n",
    "                    dtype_data[field] = dtype_data[field].astype('float64')\n",
    "                    print(f\"Converted {dtype}.{field} from uint64 to float64.\")\n",
    "                elif dtype_data[field].dtype == 'uint16':\n",
    "                    dtype_data[field] = dtype_data[field].astype('int16')\n",
    "                    print(f\"Converted {dtype}.{field} from uint16 to int16.\")\n",
    "        elif isinstance(dtype_data, pd.DataFrame):\n",
    "            # If dtype_data is a DataFrame, convert each column individually\n",
    "            for col in dtype_data.columns:\n",
    "                if dtype_data[col].dtype == 'uint32':\n",
    "                    dtype_data[col] = dtype_data[col].astype('float32')\n",
    "                    print(f\"Converted {dtype}.{col} from uint32 to float32.\")\n",
    "                elif dtype_data[col].dtype == 'uint64':\n",
    "                    dtype_data[col] = dtype_data[col].astype('float64')\n",
    "                    print(f\"Converted {dtype}.{col} from uint64 to float64.\")\n",
    "                elif dtype_data[col].dtype == 'uint16':\n",
    "                    dtype_data[col] = dtype_data[col].astype('int16')\n",
    "                    print(f\"Converted {dtype}.{col} from uint16 to int16.\")\n",
    "                \n",
    "    # Update X and layers dtypes\n",
    "    if adata.X.dtype == 'uint32':\n",
    "        adata.X = adata.X.astype('int32')\n",
    "        print(\"Converted X from uint32 to int32.\")\n",
    "    elif adata.X.dtype == 'uint64':\n",
    "        adata.X = adata.X.astype('int64')\n",
    "        print(\"Converted X from uint64 to int64.\")\n",
    "    elif adata.X.dtype == 'uint16':\n",
    "        adata.X = adata.X.astype('int16')\n",
    "        print(\"Converted X from uint16 to int16.\")\n",
    "    for layer_key, layer_val in adata.layers.items():\n",
    "        if layer_val.dtype == 'uint32':\n",
    "            adata.layers[layer_key] = layer_val.astype('int32')\n",
    "            print(f\"Converted layer {layer_key} from uint32 to int32.\")\n",
    "        elif layer_val.dtype == 'uint64':\n",
    "            adata.layers[layer_key] = layer_val.astype('int64')\n",
    "            print(f\"Converted layer {layer_key} from uint64 to int64.\")\n",
    "        elif layer_val.dtype == 'uint16':\n",
    "            adata.layers[layer_key] = layer_val.astype('int16')\n",
    "            print(f\"Converted layer {layer_key} from uint16 to int16.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in adata_dict.values():\n",
    "    convert_uint_to_int_single(adata)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732ced6",
   "metadata": {},
   "source": [
    "# Selection based on deviance (needs more work, not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import anndata2ri\n",
    "# import logging\n",
    "# import rpy2.rinterface_lib.callbacks as rcb\n",
    "# import rpy2.robjects as robjects\n",
    "\n",
    "# rcb.logger.setLevel(logging.ERROR)\n",
    "# robjects.pandas2ri.activate()\n",
    "# anndata2ri.activate()\n",
    "\n",
    "# #Loading the rpy2 extension enables cell/line magic to be used\n",
    "# %load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eebc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%R\n",
    "# BiocManager::install(\"scry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c01f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for adata in adata_dict.values():\n",
    "#     print(adata.X[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_and_select_deviant(anndata_obj: anndata.AnnData, obs_var: str, target_genes: int) -> anndata.AnnData:\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     # First, make a copy of the input anndata object\n",
    "#     anndata_copy = anndata_obj.copy()\n",
    "    \n",
    "#     n_batches = len(anndata_copy.obs[obs_var].cat.categories)\n",
    "#     print(f'splitting into {n_batches} batches for deviance calculation')\n",
    "    \n",
    "#     # Split the data by the provided observation variable for batch-aware deviance selection\n",
    "#     groups = anndata_copy.obs[obs_var].unique() \n",
    "#     split_data = [anndata_copy[anndata_copy.obs[obs_var] == group] for group in groups]\n",
    "    \n",
    "#     # Calculate deviance for each group and store highly deviant genes separately\n",
    "#     highly_deviant_genes = []\n",
    "#     df = []\n",
    "#     gene_list = anndata_copy.var_names\n",
    "#     highly_deviant_genes_per_batch = {}\n",
    "\n",
    "#     for i, data in enumerate(split_data):\n",
    "#         name=data.obs['sampletype'][0]\n",
    "#         print(f'Counting deviance for {name}')\n",
    "#         temp_counts = data.X.T\n",
    "#         robjects.globalenv['temp_counts'] = temp_counts\n",
    "#         robjects.r('library(SingleCellExperiment)')\n",
    "#         robjects.r('library(scry)')\n",
    "#         robjects.r('sce <- SingleCellExperiment(list(counts=temp_counts))')\n",
    "#         robjects.r('sce <- devianceFeatureSelection(sce, assay=\"counts\")')\n",
    "#         binomial_deviance = robjects.r(\"rowData(sce)$binomial_deviance\").T\n",
    "#         idx = binomial_deviance.argsort()[-target_genes:]\n",
    "#         mask = np.zeros(data.var_names.shape, dtype=bool)\n",
    "#         mask[idx] = True\n",
    "\n",
    "#         data.var[\"highly_deviant\"] = mask\n",
    "#         data.var[\"binomial_deviance\"] = binomial_deviance\n",
    "#         split_data[i] = data\n",
    "        \n",
    "#         highly_deviant_genes.append(data.var_names[mask])\n",
    "#         highly_deviant_genes_per_batch[name] = data.var_names[mask]\n",
    "    \n",
    "        \n",
    "#     # Merge the split data back together using `anndata.concat`\n",
    "#     print('Merging data')\n",
    "#     merged_data = anndata.concat(split_data, join='outer', index_unique=None)\n",
    "    \n",
    "#     # Calculate overall deviance across all groups and rank genes accordingly\n",
    "#     print('Calculating overall deviance and ranking genes')\n",
    "#     binomial_deviance = merged_data.var[\"binomial_deviance\"].values\n",
    "#     gene_names = merged_data.var_names.values\n",
    "#     overall_deviance_df = pd.DataFrame({\"gene_name\": gene_names, \"binomial_deviance\": binomial_deviance})\n",
    "#     overall_deviance_df.sort_values(by=\"binomial_deviance\", ascending=False, inplace=True)\n",
    "\n",
    "#     # Select the top `target_genes` highly deviant genes\n",
    "#     top_highly_deviant_genes = overall_deviance_df[\"gene_name\"].iloc[:target_genes].values\n",
    "\n",
    "#     # Update the \"highly_deviant\" column in the merged Anndata object\n",
    "#     merged_data.var[\"highly_deviant\"] = np.isin(gene_names, top_highly_deviant_genes)\n",
    "    \n",
    "#     # Assign batch-specific highly deviant genes to the merged data\n",
    "#     merged_data.var[\"highly_deviant\"] = np.isin(merged_data.var_names, np.concatenate(highly_deviant_genes))\n",
    "    \n",
    "#     del anndata_copy\n",
    "#     del split_data\n",
    "#     del groups\n",
    "    \n",
    "#     return merged_data\n",
    "    \n",
    "    # Select deviances of genes that are highly variable in all batches except one\n",
    "    #all_deviances = np.concatenate(highly_deviant_genes)\n",
    "    #highly_variable_deviances = all_deviances[\n",
    "    #    np.sum(all_deviances.mask, axis=0) == n_batches - 1\n",
    "    #]\n",
    "    #highly_variable_deviances.sort_values(ascending=False, inplace=True)\n",
    "    \n",
    "    #return highly_variable_deviances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac001b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_and_select_deviant(anndata_obj: anndata.AnnData, obs_var: str, target_genes: int) -> anndata.AnnData:\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "#     anndata_copy = anndata_obj.copy()\n",
    "    \n",
    "#     n_batches = len(anndata_copy.obs[obs_var].cat.categories)\n",
    "#     print(f'splitting into {n_batches} batches for deviance calculation')\n",
    "    \n",
    "#     # Split the data by the provided observation variable for batch-aware deviance selection\n",
    "#     groups = anndata_copy.obs[obs_var].unique() \n",
    "#     split_data = [anndata_copy[anndata_copy.obs[obs_var] == group] for group in groups]\n",
    "    \n",
    "#     # Calculate deviance for each group and store highly deviant genes separately\n",
    "#     df = []\n",
    "#     gene_list = anndata_copy.var_names\n",
    "#     highly_deviant_genes_per_batch = []\n",
    "#     highly_variable_nbatches = np.zeros(len(gene_list), dtype=int)\n",
    "\n",
    "#     for i, data in enumerate(split_data):\n",
    "#         name=data.obs['sampletype'][0]\n",
    "#         print(f'Counting deviance for {name}')\n",
    "#         temp_counts = data.X.T\n",
    "#         robjects.globalenv['temp_counts'] = temp_counts\n",
    "#         robjects.r('library(SingleCellExperiment)')\n",
    "#         robjects.r('library(scry)')\n",
    "#         robjects.r('sce <- SingleCellExperiment(list(counts=temp_counts))')\n",
    "#         robjects.r('sce <- devianceFeatureSelection(sce, assay=\"counts\")')\n",
    "#         binomial_deviance = robjects.r(\"rowData(sce)$binomial_deviance\").T\n",
    "#         idx = binomial_deviance.argsort()[-target_genes:]\n",
    "#         mask = np.zeros(data.var_names.shape, dtype=bool)\n",
    "#         mask[idx] = True\n",
    "\n",
    "#         data.var[\"highly_deviant\"] = mask\n",
    "#         data.var[\"binomial_deviance\"] = binomial_deviance\n",
    "#         split_data[i] = data\n",
    "        \n",
    "#         highly_deviant_genes_per_batch.append(data.var_names[mask])\n",
    "#         highly_variable_nbatches[mask] += 1\n",
    "    \n",
    "        \n",
    "#     # Merge the split data back together using `anndata.concat`\n",
    "#     print('Merging data')\n",
    "#     merged_data = anndata.concat(split_data, join='outer', index_unique=None)\n",
    "    \n",
    "#     # Create a new variable 'highly_variable_nbatches' in the merged Anndata object\n",
    "#     merged_data.var[\"highly_variable_nbatches\"] = highly_variable_nbatches\n",
    "        \n",
    "#     del anndata_copy\n",
    "#     del split_data\n",
    "#     del groups\n",
    "    \n",
    "#     # Create 'nbatch1_deviances' variable to retain highly deviant genes present in all batches\n",
    "#     nbatch1_deviances = merged_data.var[\"binomial_deviance\"][\n",
    "#         merged_data.var[\"highly_variable_nbatches\"] >= len(merged_data.obs[obs_var].cat.categories) - 1\n",
    "#     ]\n",
    "\n",
    "#     # Sort the deviances in descending order\n",
    "#     nbatch1_deviances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "#     if len(nbatch1_deviances) > target_genes:\n",
    "#         hvg = nbatch1_deviances.index[:target_genes]\n",
    "\n",
    "#     else:\n",
    "#         enough = False\n",
    "#         print(f\"Using {len(nbatch1_deviances)} HVGs from full intersect set\")\n",
    "#         hvg = nbatch1_deviances.index[:]\n",
    "#         not_n_batches = 1\n",
    "\n",
    "#         while not enough:\n",
    "#             target_genes_diff = target_genes - len(hvg)\n",
    "\n",
    "#             tmp_dispersions = merged_data.var[\"binomial_deviance\"][\n",
    "#                 merged_data.var.highly_variable_nbatches == (n_batches - not_n_batches)\n",
    "#             ]\n",
    "\n",
    "#             if len(tmp_dispersions) < target_genes_diff:\n",
    "#                 print(\n",
    "#                     f\"Using {len(tmp_dispersions)} HVGs from n_batch-{not_n_batches} set\"\n",
    "#                 )\n",
    "#                 hvg = hvg.append(tmp_dispersions.index)\n",
    "#                 not_n_batches += 1\n",
    "\n",
    "#             else:\n",
    "#                 print(\n",
    "#                     f\"Using {target_genes_diff} HVGs from n_batch-{not_n_batches} set\"\n",
    "#                 )\n",
    "#                 tmp_dispersions.sort_values(ascending=False, inplace=True)\n",
    "#                 hvg = hvg.append(tmp_dispersions.index[:target_genes_diff])\n",
    "#                 enough = True\n",
    "\n",
    "#     print(f\"Using {len(hvg)} HVGs\")\n",
    "\n",
    "#     return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368c62a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# deviant_adata = {}\n",
    "# for i, adata in adata_dict.items():\n",
    "#     deviant_adata[i] = select_deviant(adata, 4000)\n",
    "# deviant_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f40a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert adata_dict.keys() == deviant_adata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in adata_dict.keys():\n",
    "#    adata_dict[i].var['highly_deviant'] = deviant_adata[i].var['highly_deviant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d674831",
   "metadata": {},
   "source": [
    "### scIB:\n",
    "Batch-aware highly variable gene selection\n",
    "\n",
    "Method to select HVGs based on mean dispersions of genes that are highly variable genes in all batches. Using a the top target_genes per batch by average normalize dispersion. If target genes still hasn’t been reached, then HVGs in all but one batches are used to fill up. This is continued until HVGs in a single batch are considered.\n",
    "\n",
    "Parameters:\n",
    "- adata – anndata object\n",
    "- batch – adata.obs column\n",
    "- target_genes – maximum number of genes (intersection reduces the number of genes)\n",
    "- flavor – parameter for scanpy.pp.highly_variable_genes\n",
    "- n_bins – parameter for scanpy.pp.highly_variable_genes\n",
    "- adataOut – whether to return an anndata object or a list of highly variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    adata_dict[i].X = adata_dict[i].layers['log1p_norm'].copy()\n",
    "    print(adata_dict[i].X[0:5, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad1b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scib\n",
    "\n",
    "for i, adata in adata_dict.items():\n",
    "    scib.preprocessing.hvg_batch(adata, \n",
    "                                 batch_key=\"sampletype\",\n",
    "                                 target_genes=3500, \n",
    "                                 flavor='cell_ranger', \n",
    "                                 n_bins=20, \n",
    "                                 adataOut=True\n",
    "                                )\n",
    "\n",
    "    sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d300afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches={}\n",
    "for i, (name, adata) in enumerate(adata_dict.items()):\n",
    "    n_batches[i] = adata.var[\"highly_variable_nbatches\"].value_counts()\n",
    "    #ax[i] = n_batches[i].plot(kind=\"bar\")\n",
    "    print(n_batches[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, adata in adata_dict.items():\n",
    "#     ax = sns.scatterplot(\n",
    "#         data=adata.var, x=\"means\", y=\"dispersions\", hue=\"highly_deviant\", s=5\n",
    "#     )\n",
    "#     ax.set_xlim(None, 1.5)\n",
    "#     ax.set_ylim(None, 3)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514207c5",
   "metadata": {},
   "source": [
    "Most genes are not highly variable. By selecting the top 3500 genes, we capture HVGs that are variable in at least 2+ batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95878bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del deviant_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    # check that variables are unique:\n",
    "    assert len(adata.var_names) == len(set(adata.var_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    annot = sc.queries.biomart_annotations(\n",
    "        \"hsapiens\",\n",
    "        [\"ensembl_gene_id\", \"external_gene_name\", \"start_position\", \"end_position\", \"chromosome_name\"],\n",
    "    ).set_index(\"ensembl_gene_id\")\n",
    "\n",
    "    adata.var[annot.columns] = annot\n",
    "\n",
    "    adata.var.rename(columns={\"external_gene_name\": \"Gene\"}, inplace=True)\n",
    "    adata.var['ensembl_gene_id'] = adata.var.index\n",
    "    adata.var['Gene'] = adata.var['Gene'].fillna(adata.var['ensembl_gene_id'])\n",
    "    adata.obs.index.name = 'CellID'\n",
    "    adata.var.index = adata.var[\"Gene\"]\n",
    "    adata.var_names_make_unique()\n",
    "    adata_dict[i] = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a01c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_dict['dev_adata'].var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_dict['adult_adata'].var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc84ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    print(f\"Before filtering: {adata.n_vars} genes\")\n",
    "    # check if MALAT1 gene is in the gene list\n",
    "    if 'MALAT1' in adata.var_names:\n",
    "        # create a list of genes to keep\n",
    "        gene_list = adata.var_names != 'MALAT1'\n",
    "        # slice the anndata object to select all genes except for MALAT1\n",
    "        adata = adata[:, gene_list]\n",
    "        adata_dict[i] = adata\n",
    "\n",
    "    print(f\"After MALAT1 filtering: {adata.n_vars} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    # mitochondrial genes\n",
    "    adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "    # ribosomal genes\n",
    "    adata.var[\"ribo\"] = adata.var_names.str.startswith((\"RPS\", \"RPL\"))\n",
    "    # hemoglobin genes.\n",
    "    # adata.var[\"hb\"] = adata.var_names.str.contains((\"^HB[^(P)]\"))\n",
    "\n",
    "    # sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\", \"ribo\", \"hb\"], inplace=True, percent_top=[20], log1p=False)\n",
    "    # Filter out mitochondrial and ribosomal genes\n",
    "    #print(f\"Before filtering: {adata.n_vars} genes\")\n",
    "    #mt_genes = adata.var_names[adata.var['mt']]  # list of mitochondrial genes\n",
    "    #ribo_genes = adata.var_names[adata.var['ribo']]  # list of ribosomal genes\n",
    "    #genes_to_remove = np.concatenate([mt_genes, ribo_genes])\n",
    "    #adata = adata[:, ~adata.var_names.isin(genes_to_remove)]\n",
    "    #print(f\"After filtering: {adata.n_vars} genes\")\n",
    "\n",
    "    # Calculate n_counts and n_genes\n",
    "    adata.obs['n_counts'] = adata.X.sum(axis=1)\n",
    "    adata.obs['n_genes'] = (adata.X > 0).sum(axis=1)\n",
    "    \n",
    "    adata_dict[i] = adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd52d76",
   "metadata": {},
   "source": [
    "# SAMPLE SEX DETERMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    # check if there is XIST expression\n",
    "    if any(adata.var_names.str.match('XIST')) == True:\n",
    "        chrY_genes = adata.var_names.intersection(annot.index[annot.chromosome_name == \"Y\"])\n",
    "\n",
    "        adata.obs['percent_chrY'] = np.sum(\n",
    "            adata[:, chrY_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1 * 100\n",
    "\n",
    "        # color inputs must be from either .obs or .var, so add in XIST expression to obs.\n",
    "        adata.obs[\"XIST-counts\"] = adata.X[:,adata.var_names.str.match('XIST')].toarray()\n",
    "\n",
    "        sc.pl.violin(adata, [\"XIST-counts\", \"percent_chrY\"], jitter=0.4, groupby = 'sample', rotation= 90, save=f'{i}_XIST.svg')\n",
    "        adata_dict[i] = adata\n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d22e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    # Calculate median XIST-counts and percent_chrY values for each sample\n",
    "    sample_medians = adata.obs.groupby('sample')['XIST-counts', 'percent_chrY'].median()\n",
    "\n",
    "    # Define female and male criteria based on median XIST-counts and percent_chrY\n",
    "    female_criteria = (sample_medians['XIST-counts'] > 0.5)\n",
    "    male_criteria = (sample_medians['XIST-counts'] < 0.5)\n",
    "\n",
    "    # Create a new categorical variable 'sex'\n",
    "    adata.obs['sex'] = 'unknown'\n",
    "\n",
    "    # Update 'sex' based on the female and male criteria\n",
    "    for sample in sample_medians.index:\n",
    "        if female_criteria[sample]:\n",
    "            adata.obs.loc[adata.obs['sample'] == sample, 'sex'] = 'female'\n",
    "        elif male_criteria[sample]:\n",
    "            adata.obs.loc[adata.obs['sample'] == sample, 'sex'] = 'male'\n",
    "\n",
    "    # Print the names of female and male samples\n",
    "    female_samples = adata.obs.loc[adata.obs['sex'] == 'female', 'sample'].unique()\n",
    "    male_samples = adata.obs.loc[adata.obs['sex'] == 'male', 'sample'].unique()\n",
    "    \n",
    "    adata_dict[i] = adata\n",
    "\n",
    "    print(f\"Female samples: {', '.join(female_samples)}\")\n",
    "    print(f\"Male samples: {', '.join(male_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee6e5c1",
   "metadata": {},
   "source": [
    "# CELL CYCLE PHASE DETERMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    # Count number of genes before removing zero count genes\n",
    "    print(adata.shape[1])\n",
    "    # Remove genes with zero counts\n",
    "    sc.pp.filter_genes(adata, min_counts=5, inplace=True)\n",
    "    sc.pp.filter_cells(adata, min_genes=200)\n",
    "    # Count number of genes after removing zero count genes\n",
    "    print(adata.shape[1])\n",
    "    adata_dict[i] = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    adata.raw = adata.copy()\n",
    "    adata_dict[i] = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    adata.obs['libbatch'] = adata.obs['libbatch'].astype('category')\n",
    "    adata.obs['sample'] = adata.obs['sample'].astype('category')\n",
    "\n",
    "    scib.preprocessing.score_cell_cycle(adata, organism='human')\n",
    "    sc.pl.violin(adata, ['S_score', 'G2M_score'],\n",
    "                 jitter=0.4, groupby = 'sample', rotation=90, \n",
    "                 save=f'{i}_cell_cycle.svg'\n",
    "                )\n",
    "    adata_dict[i] = adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ab1af",
   "metadata": {},
   "source": [
    "# DIMENSIONALITY REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_scale(anndata_obj: anndata.AnnData, obs_var: str) -> anndata.AnnData:\n",
    "    \"\"\"\n",
    "    Splits anndata object into separate objects based on the given observation variable, scales each object using\n",
    "    `sc.pp.scale` and merges them back together using `anndata.concat`.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    anndata_obj: anndata.AnnData\n",
    "        Annotated data matrix with normalized, log-transformed counts.\n",
    "    obs_var: str\n",
    "        Observation variable to split the data on.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if anndata.X is log-transformed and normalised\n",
    "    if np.min(anndata_obj.X) >= 1:\n",
    "        raise ValueError(\"Anndata object X is not log-transformed.\")\n",
    "    if np.max(anndata_obj.X) > 10:\n",
    "        raise ValueError(\"Anndata object X is not normalised.\")\n",
    "    \n",
    "    # First, make a copy of the input anndata object\n",
    "    anndata_copy = anndata_obj.copy()\n",
    "    \n",
    "    # Split the data by the provided observation variable\n",
    "    groups = anndata_copy.obs[obs_var].unique()\n",
    "    split_data = [anndata_copy[anndata_copy.obs[obs_var] == group] for group in groups]\n",
    "    \n",
    "    # Scale each split data object using `sc.pp.scale`\n",
    "    for i, data in enumerate(split_data):\n",
    "        sc.pp.scale(data)\n",
    "        split_data[i] = data\n",
    "        \n",
    "    # Merge the split data back together using `anndata.concat`\n",
    "    merged_data = anndata.concat(split_data, join='outer', index_unique=None)\n",
    "    \n",
    "    del anndata_copy\n",
    "    del split_data\n",
    "    del groups\n",
    "    \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044af132",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_adata = {}\n",
    "for i, adata in adata_dict.items():\n",
    "    scaled_adata[i] = split_and_scale(adata, 'sample')\n",
    "    print(scaled_adata[i].X[1:10,1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ff06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert adata_dict.keys() == scaled_adata.keys()\n",
    "for i, adata in adata_dict.items():\n",
    "    adata_dict[i].layers['scaled'] = scaled_adata[i].X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a568388",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    print(adata_dict[i].layers['scaled'][0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del scaled_adata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    adata.obsm[\"X_pca\"] = sc.pp.pca(adata[:,adata.var.highly_variable].layers[\"scaled\"], n_comps=50, svd_solver=\"arpack\")\n",
    "    adata_dict[i] = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817effd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(anndata, parameters: list, components: list, filename: str):\n",
    "    n_plots = len(parameters)\n",
    "    fig, axs = plt.subplots(n_plots, 1, figsize=(4, 3*n_plots))\n",
    "    for i, param in enumerate(parameters):\n",
    "        sc.pl.pca(anndata, color=param, ax=axs[i], show=False, components = components, frameon=False)\n",
    "        axs[i].set_title(param)\n",
    "    plt.tight_layout()\n",
    "    savesvg(filename, fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230bc74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pca(adata_dict['adult_adata'], ['sampletype', 'age', 'libbatch', 'sample', 'type', 'phase', 'sex'], \n",
    "     components = ['1,2'], filename = 'adult_PC1vs2_plots.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(anndata, parameters: list, components: list, filename: str):\n",
    "    n_plots = len(parameters)\n",
    "    fig, axs = plt.subplots(n_plots, 1, figsize=(7, 4*n_plots))\n",
    "    for i, param in enumerate(parameters):\n",
    "        sc.pl.pca(anndata, color=param, ax=axs[i], show=False, components = components, frameon=False)\n",
    "        axs[i].set_title(param)\n",
    "    plt.tight_layout()\n",
    "    savesvg(filename, fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20acb057",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pca(adata_dict['dev_adata'], ['sampletype', 'age', 'libbatch', 'sample', 'type', 'phase', 'sex'], \n",
    "     components = ['1,2'], filename = 'dev_PC1vs2_plots.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a622ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pca(adata, ['sampletype', 'age', 'libbatch', 'sample', 'type', 'phase', 'sex'], \n",
    "         components = ['3,4'], filename=f'PC3vs4_plots.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c638e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    sc.pp.neighbors(adata, n_neighbors=30, n_pcs=15)\n",
    "    sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99440a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umaps(anndata, parameters: list, filename: str):\n",
    "    n_plots = len(parameters)\n",
    "    fig, axs = plt.subplots(n_plots, 1, figsize=(4, 3*n_plots))\n",
    "    for i, param in enumerate(parameters):\n",
    "        sc.pl.umap(anndata, color=param, ax=axs[i], show=False, frameon=False)\n",
    "        axs[i].set_title(param)\n",
    "    plt.tight_layout()\n",
    "    savesvg(filename, fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2ede0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_umaps(adata_dict['adult_adata'], ['sampletype', 'age', 'agegroup', 'libbatch', 'sample', 'type', 'phase', 'sex'], \n",
    "           filename = 'adult_UMAP_plots.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85620648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umaps(anndata, parameters: list, filename: str):\n",
    "    n_plots = len(parameters)\n",
    "    fig, axs = plt.subplots(n_plots, 1, figsize=(7, 4*n_plots))\n",
    "    for i, param in enumerate(parameters):\n",
    "        sc.pl.umap(anndata, color=param, ax=axs[i], show=False, frameon=False)\n",
    "        axs[i].set_title(param)\n",
    "    plt.tight_layout()\n",
    "    savesvg(filename, fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292405d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_umaps(adata_dict['dev_adata'], ['sampletype', 'age', 'agegroup', 'libbatch', 'sample', 'type', 'phase', 'sex'], \n",
    "           filename = 'dev_UMAP_plots.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d618c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_umaps(adata, ['sampletype', 'age', 'agegroup', 'libbatch', 'sample', 'type', 'phase', 'sex'], \n",
    "           filename = 'UMAP_plots.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395924dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umaps2(anndata, parameters: list, filename: str):\n",
    "    n_plots = len(parameters)\n",
    "    fig, axs = plt.subplots(n_plots, 1, figsize=(4, 10))\n",
    "    for i, param in enumerate(parameters):\n",
    "        sc.pl.umap(anndata, color=param, ax=axs[i], show=False, frameon=False)\n",
    "        axs[i].set_title(param)\n",
    "    plt.tight_layout()\n",
    "    savesvg(filename, fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97320e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umaps2(adata_dict['adult_adata'], [\"n_counts\", \"n_genes\", \"pct_counts_mt\"], \n",
    "            filename = 'adult_UMAPparameter_plots.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umaps2(adata_dict['dev_adata'], [\"n_counts\", \"n_genes\", \"pct_counts_mt\"], \n",
    "            filename = 'dev_UMAPparameter_plots.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22704a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_umaps2(adata, [\"n_counts\", \"n_genes\", \"pct_counts_mt\"], \n",
    "            filename = 'UMAPparameter_plots.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f49172",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in adata_dict.values():\n",
    "    sc.tl.leiden(adata, resolution=0.5, key_added='leiden_05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for adata in adata_dict.values():\n",
    "    sc.pl.umap(adata, color='leiden_05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    print(i, adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, adata in adata_dict.items():\n",
    "    adata.write(os.path.join(RESULTS_FOLDERNAME, f'{i}_normalized.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280e74a1",
   "metadata": {},
   "source": [
    "# EXTRA (do not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_adata.var_names_make_unique()\n",
    "adult_adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f344fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_adata.var = dev_adata.var.drop(['Gene'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_adata = sc.read_h5ad(os.path.join(RESULTS_FOLDERNAME, 'dev_adata_normalized.h5ad'))\n",
    "adult_adata = sc.read_h5ad(os.path.join(RESULTS_FOLDERNAME, 'adult_adata_normalized.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902703c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_adata.var.index.name='Genes'\n",
    "adult_adata.var = adult_adata.var.drop(['Gene'], axis=1)\n",
    "adult_adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc9492",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_adata.write(os.path.join(RESULTS_FOLDERNAME, f'dev_adata_normalized.h5ad'))\n",
    "adult_adata.write(os.path.join(RESULTS_FOLDERNAME, f'adult_adata_normalized.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef188de",
   "metadata": {},
   "source": [
    "this was run for scIB integration benchmarking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scib-pipeline-R4.0]",
   "language": "python",
   "name": "conda-env-scib-pipeline-R4.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
